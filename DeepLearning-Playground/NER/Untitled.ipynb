{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-26T20:37:56.638Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-27 02:07:57,553 http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz not found in cache, downloading to /var/folders/5m/h_g_92_s1d11s4pd5cbhs48m0000gn/T/tmpj5i_8fv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84125825/84125825 [00:15<00:00, 5410086.70B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-27 02:08:13,723 copying /var/folders/5m/h_g_92_s1d11s4pd5cbhs48m0000gn/T/tmpj5i_8fv2 to cache at /Users/subir/.flair/datasets/imdb_v2-rebalanced/aclImdb_v1.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-27 02:08:14,000 removing temp file /var/folders/5m/h_g_92_s1d11s4pd5cbhs48m0000gn/T/tmpj5i_8fv2\n",
      "2020-06-27 02:08:38,777 Reading data from /Users/subir/.flair/datasets/imdb_v2-rebalanced\n",
      "2020-06-27 02:08:38,777 Train: /Users/subir/.flair/datasets/imdb_v2-rebalanced/train-all.txt\n",
      "2020-06-27 02:08:38,778 Dev: None\n",
      "2020-06-27 02:08:38,779 Test: None\n",
      "Dictionary with 5 tags: <unk>, O, , <START>, <STOP>\n",
      "2020-06-27 02:09:10,563 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-27 02:09:10,565 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings('glove')\n",
      "    (list_embedding_1): CharacterEmbeddings(\n",
      "      (char_embedding): Embedding(275, 25)\n",
      "      (char_rnn): LSTM(25, 25, bidirectional=True)\n",
      "    )\n",
      "    (list_embedding_2): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.05, inplace=False)\n",
      "        (encoder): Embedding(300, 100)\n",
      "        (rnn): LSTM(100, 2048)\n",
      "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (list_embedding_3): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.05, inplace=False)\n",
      "        (encoder): Embedding(300, 100)\n",
      "        (rnn): LSTM(100, 2048)\n",
      "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=4246, out_features=4246, bias=True)\n",
      "  (rnn): LSTM(4246, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=5, bias=True)\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2020-06-27 02:09:10,566 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-27 02:09:10,567 Corpus: \"Corpus: 4050 train + 450 dev + 500 test sentences\"\n",
      "2020-06-27 02:09:10,569 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-27 02:09:10,570 Parameters:\n",
      "2020-06-27 02:09:10,571  - learning_rate: \"0.1\"\n",
      "2020-06-27 02:09:10,572  - mini_batch_size: \"32\"\n",
      "2020-06-27 02:09:10,573  - patience: \"3\"\n",
      "2020-06-27 02:09:10,574  - anneal_factor: \"0.5\"\n",
      "2020-06-27 02:09:10,575  - max_epochs: \"2\"\n",
      "2020-06-27 02:09:10,576  - shuffle: \"True\"\n",
      "2020-06-27 02:09:10,577  - train_with_dev: \"False\"\n",
      "2020-06-27 02:09:10,579  - batch_growth_annealing: \"False\"\n",
      "2020-06-27 02:09:10,580 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-27 02:09:10,581 Model training base path: \"resources/taggers/example-pos\"\n",
      "2020-06-27 02:09:10,582 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-27 02:09:10,583 Device: cpu\n",
      "2020-06-27 02:09:10,585 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-27 02:09:10,586 Embeddings storage mode: cpu\n",
      "2020-06-27 02:09:10,593 ----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Corpus\n",
    "from flair.datasets import UD_ENGLISH\n",
    "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings\n",
    "from flair.embeddings import CharacterEmbeddings\n",
    "corpus = flair.datasets.IMDB().downsample(0.1)\n",
    "\n",
    "# 2. what tag do we want to predict?\n",
    "tag_type = 'ner'\n",
    "\n",
    "# 3. make the tag dictionary from the corpus\n",
    "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n",
    "print(tag_dictionary)\n",
    "\n",
    "# 4. initialize embeddings\n",
    "embedding_types = [\n",
    "    \n",
    "    WordEmbeddings('glove'),\n",
    "\n",
    "    # comment in this line to use character embeddings\n",
    "    CharacterEmbeddings(),\n",
    "\n",
    "    # comment in these lines to use flair embeddings\n",
    "    FlairEmbeddings('news-forward'),\n",
    "    FlairEmbeddings('news-backward'),\n",
    "    \n",
    "]\n",
    "\n",
    "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)\n",
    "\n",
    "# 5. initialize sequence tagger\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n",
    "                                        embeddings=embeddings,\n",
    "                                        tag_dictionary=tag_dictionary,\n",
    "                                        tag_type=tag_type,\n",
    "                                        use_crf=True)\n",
    "\n",
    "# 6. initialize trainer\n",
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "trainer: ModelTrainer = ModelTrainer(tagger, corpus)\n",
    "\n",
    "# 7. start training\n",
    "trainer.train('resources/taggers/example-pos',\n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=32,\n",
    "              max_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-26T20:21:20.460310Z",
     "start_time": "2020-06-26T20:21:17.307020Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-27 01:51:17,327 loading file resources/taggers/example-pos/final-model.pt\n",
      "I <PRP> love <VBP> Berlin <NNP>\n"
     ]
    }
   ],
   "source": [
    "# load the model you trained\n",
    "model = SequenceTagger.load('resources/taggers/example-pos/final-model.pt')\n",
    "\n",
    "# create example sentence\n",
    "sentence = Sentence('I love Berlin')\n",
    "\n",
    "# predict tags and print\n",
    "model.predict(sentence)\n",
    "\n",
    "print(sentence.to_tagged_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python37464bitd354516f517147279a113529c8fe5e5f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
