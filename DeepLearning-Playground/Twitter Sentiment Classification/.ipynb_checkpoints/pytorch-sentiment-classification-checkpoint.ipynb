{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T22:01:59.711427Z",
     "start_time": "2020-06-05T22:01:58.819072Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "from torchtext.datasets import text_classification\n",
    "NGRAMS = 2\n",
    "import os\n",
    "BATCH_SIZE = 16\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T22:27:02.923345Z",
     "start_time": "2020-06-05T22:27:02.904089Z"
    }
   },
   "outputs": [],
   "source": [
    "#Reproducing same results\n",
    "SEED = 2019\n",
    "\n",
    "#Torch\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "#Cuda algorithms\n",
    "torch.backends.cudnn.deterministic = True  \n",
    "\n",
    "#handling text data\n",
    "from torchtext import data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T22:27:05.385822Z",
     "start_time": "2020-06-05T22:27:05.381440Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T22:27:06.104171Z",
     "start_time": "2020-06-05T22:27:06.100635Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchtext.data.utils import ngrams_iterator\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T22:27:07.291048Z",
     "start_time": "2020-06-05T22:27:07.283738Z"
    }
   },
   "outputs": [],
   "source": [
    "def text_preprocessing(text_list):\n",
    "    clean_text=\" \".join(text_list)\n",
    "    clean_text = clean_text.replace(\"[^a-zA-Z0-9#]\", \" \")\n",
    "    clean_text = clean_text.replace('#', 'hashtag ')\n",
    "    clean_text = tknzr.tokenize(clean_text)\n",
    "    return clean_text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T22:07:20.424731Z",
     "start_time": "2020-06-05T22:07:11.571042Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/subir/Environment/python/base/lib/python3.8/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/Users/subir/Environment/python/base/lib/python3.8/site-packages/torchtext/data/field.py:150: UserWarning: LabelField class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "TEXT = data.Field(tokenize=\"spacy\",\n",
    "                  batch_first=True,\n",
    "                  include_lengths=True,\n",
    "                  lower=True,\n",
    "                  stop_words=set(stopwords.words('english')))\n",
    "LABEL = data.LabelField(dtype=torch.float, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T22:07:20.453266Z",
     "start_time": "2020-06-05T22:07:20.449126Z"
    }
   },
   "outputs": [],
   "source": [
    "fields = [(None, None),('label', LABEL) ,('text',TEXT)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T22:07:27.970018Z",
     "start_time": "2020-06-05T22:07:20.473491Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/subir/Environment/python/base/lib/python3.8/site-packages/torchtext/data/example.py:68: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n",
      "/Users/subir/Environment/python/base/lib/python3.8/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': '0', 'text': [' ', '@user', 'father', 'dysfunctional', 'selfish', 'drags', 'kids', 'dysfunction', '.', '  ', '#', 'run']}\n"
     ]
    }
   ],
   "source": [
    "# loading custom train dataset\n",
    "training_data = data.TabularDataset(path='./data/train.csv',\n",
    "                                    format='csv',\n",
    "                                    fields=fields,\n",
    "                                    skip_header=True)\n",
    "\n",
    "# print preprocessed text\n",
    "print(vars(training_data.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T22:07:32.158762Z",
     "start_time": "2020-06-05T22:07:32.085496Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "train_data, valid_data = training_data.split(split_ratio=0.9,stratified=True,random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T22:07:34.552627Z",
     "start_time": "2020-06-05T22:07:33.086308Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of TEXT vocabulary: 43853\n",
      "Size of LABEL vocabulary: 2\n",
      "[('#', 67336), (' ', 18203), ('  ', 17279), ('@user', 15636), ('!', 12848), ('.', 10941), (',', 5627), ('Â¦', 5451), (\"'s\", 2894), ('love', 2385)]\n"
     ]
    }
   ],
   "source": [
    "# initialize glove embeddings\n",
    "TEXT.build_vocab(train_data, min_freq=1, vectors=\"glove.6B.300d\")\n",
    "LABEL.build_vocab(train_data)\n",
    "\n",
    "# No. of unique tokens in text\n",
    "print(\"Size of TEXT vocabulary:\", len(TEXT.vocab))\n",
    "\n",
    "# No. of unique tokens in label\n",
    "print(\"Size of LABEL vocabulary:\", len(LABEL.vocab))\n",
    "\n",
    "# Commonly used words\n",
    "print(TEXT.vocab.freqs.most_common(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T22:07:37.931815Z",
     "start_time": "2020-06-05T22:07:37.920514Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/subir/Environment/python/base/lib/python3.8/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# check whether cuda is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# set batch size\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Load an iterator\n",
    "train_iterator, valid_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    sort_key=lambda x: len(x.text),\n",
    "    sort_within_batch=True,\n",
    "    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T22:07:38.865127Z",
     "start_time": "2020-06-05T22:07:38.853871Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class classifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim,\n",
    "                 n_layers, bidirectional, dropout):\n",
    "\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim,\n",
    "                            hidden_dim,\n",
    "                            num_layers=n_layers,\n",
    "                            bidirectional=bidirectional,\n",
    "                            dropout=dropout,\n",
    "                            batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.act = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, text, text_lengths):\n",
    "        # text = [batch size,sent_length]\n",
    "        embedded = self.embedding(text)\n",
    "        # embedded = [batch size, sent_len, emb dim]\n",
    "        # packed sequence\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded,\n",
    "                                                            text_lengths,\n",
    "                                                            batch_first=True)\n",
    "        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n",
    "        # hidden = [batch size, num layers * num directions,hid dim]\n",
    "        # cell = [batch size, num layers * num directions,hid dim]\n",
    "        # concat the final forward and backward hidden state\n",
    "        hidden = torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)\n",
    "        # hidden = [batch size, hid dim * num directions]\n",
    "        dense_outputs = self.fc(hidden)\n",
    "        # Final activation function\n",
    "        outputs = self.act(dense_outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T22:07:39.688166Z",
     "start_time": "2020-06-05T22:07:39.581149Z"
    }
   },
   "outputs": [],
   "source": [
    "# define hyperparameters\n",
    "size_of_vocab = len(TEXT.vocab)\n",
    "embedding_dim = 300\n",
    "num_hidden_nodes = 32\n",
    "num_output_nodes = 1\n",
    "num_layers = 2\n",
    "bidirection = True\n",
    "dropout = 0.5\n",
    "\n",
    "# instantiate the model\n",
    "model = classifier(size_of_vocab,\n",
    "                   embedding_dim,\n",
    "                   num_hidden_nodes,\n",
    "                   num_output_nodes,\n",
    "                   num_layers,\n",
    "                   bidirectional=True,\n",
    "                   dropout=dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T22:07:40.816944Z",
     "start_time": "2020-06-05T22:07:40.798234Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier(\n",
      "  (embedding): Embedding(43853, 300)\n",
      "  (lstm): LSTM(300, 32, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
      "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (act): Sigmoid()\n",
      ")\n",
      "The model has 13,266,557 trainable parameters\n",
      "torch.Size([43853, 300])\n"
     ]
    }
   ],
   "source": [
    "#architecture\n",
    "print(model)\n",
    "\n",
    "#No. of trianable parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "#Initialize the pretrained embedding\n",
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "\n",
    "print(pretrained_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T22:07:41.807155Z",
     "start_time": "2020-06-05T22:07:41.798809Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# define optimizer and loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.03)\n",
    "criterion = nn.BCELoss()\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)\n",
    "\n",
    "\n",
    "# define metric\n",
    "def binary_accuracy(preds, y):\n",
    "    # round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "\n",
    "    correct = (rounded_preds == y).float()\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "\n",
    "# push to cuda if available\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T22:07:42.548939Z",
     "start_time": "2020-06-05T22:07:42.539545Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, scheduler):\n",
    "\n",
    "    # initialize every epoch\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    # set the model in training phase\n",
    "    model.train()\n",
    "\n",
    "    for batch in iterator:\n",
    "\n",
    "        # resets the gradients after every batch\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # retrieve text and no. of words\n",
    "        text, text_lengths = batch.text\n",
    "\n",
    "        # convert to 1D tensor\n",
    "        predictions = model(text, text_lengths).squeeze()\n",
    "\n",
    "        # compute the loss\n",
    "        loss = criterion(predictions, batch.label)\n",
    "\n",
    "        # compute the binary accuracy\n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "        # backpropage the loss and compute the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        #loss and accuracy\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    scheduler.step()\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T22:07:43.381434Z",
     "start_time": "2020-06-05T22:07:43.371509Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "\n",
    "    # initialize every epoch\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    # deactivating dropout layers\n",
    "    model.eval()\n",
    "\n",
    "    # deactivates autograd\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for batch in iterator:\n",
    "\n",
    "            # retrieve text and no. of words\n",
    "            text, text_lengths = batch.text\n",
    "\n",
    "            # convert to 1d tensor\n",
    "            predictions = model(text, text_lengths).squeeze()\n",
    "\n",
    "            # compute loss and accuracy\n",
    "            loss = criterion(predictions, batch.label)\n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "            # keep track of loss and accuracy\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T22:09:47.949321Z",
     "start_time": "2020-06-05T22:07:44.110895Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/subir/Environment/python/base/lib/python3.8/site-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\n",
      "\tTrain Loss: 0.164 | Train Acc: 94.45%\n",
      "\t Val. Loss: 0.142 |  Val. Acc: 95.38%\n",
      "Epoch: 1\n",
      "\n",
      "\tTrain Loss: 0.135 | Train Acc: 95.17%\n",
      "\t Val. Loss: 0.165 |  Val. Acc: 94.91%\n",
      "Epoch: 2\n",
      "\n",
      "\tTrain Loss: 0.132 | Train Acc: 95.15%\n",
      "\t Val. Loss: 0.155 |  Val. Acc: 94.69%\n",
      "Epoch: 3\n",
      "\n",
      "\tTrain Loss: 0.132 | Train Acc: 95.29%\n",
      "\t Val. Loss: 0.137 |  Val. Acc: 94.91%\n",
      "Epoch: 4\n",
      "\n",
      "\tTrain Loss: 0.129 | Train Acc: 95.47%\n",
      "\t Val. Loss: 0.145 |  Val. Acc: 95.16%\n",
      "Epoch: 5\n",
      "\n",
      "\tTrain Loss: 0.128 | Train Acc: 95.31%\n",
      "\t Val. Loss: 0.148 |  Val. Acc: 95.09%\n",
      "Epoch: 6\n",
      "\n",
      "\tTrain Loss: 0.127 | Train Acc: 95.46%\n",
      "\t Val. Loss: 0.149 |  Val. Acc: 94.78%\n",
      "Epoch: 7\n",
      "\n",
      "\tTrain Loss: 0.124 | Train Acc: 95.39%\n",
      "\t Val. Loss: 0.152 |  Val. Acc: 94.68%\n",
      "Epoch: 8\n",
      "\n",
      "\tTrain Loss: 0.123 | Train Acc: 95.54%\n",
      "\t Val. Loss: 0.143 |  Val. Acc: 94.94%\n",
      "Epoch: 9\n",
      "\n",
      "\tTrain Loss: 0.123 | Train Acc: 95.44%\n",
      "\t Val. Loss: 0.137 |  Val. Acc: 95.16%\n",
      "Epoch: 10\n",
      "\n",
      "\tTrain Loss: 0.117 | Train Acc: 95.76%\n",
      "\t Val. Loss: 0.144 |  Val. Acc: 95.44%\n",
      "Epoch: 11\n",
      "\n",
      "\tTrain Loss: 0.112 | Train Acc: 95.89%\n",
      "\t Val. Loss: 0.130 |  Val. Acc: 95.66%\n",
      "Epoch: 12\n",
      "\n",
      "\tTrain Loss: 0.106 | Train Acc: 96.19%\n",
      "\t Val. Loss: 0.148 |  Val. Acc: 95.16%\n",
      "Epoch: 13\n",
      "\n",
      "\tTrain Loss: 0.107 | Train Acc: 96.22%\n",
      "\t Val. Loss: 0.125 |  Val. Acc: 95.50%\n",
      "Epoch: 14\n",
      "\n",
      "\tTrain Loss: 0.106 | Train Acc: 96.24%\n",
      "\t Val. Loss: 0.125 |  Val. Acc: 95.69%\n",
      "Epoch: 15\n",
      "\n",
      "\tTrain Loss: 0.101 | Train Acc: 96.25%\n",
      "\t Val. Loss: 0.136 |  Val. Acc: 95.75%\n",
      "Epoch: 16\n",
      "\n",
      "\tTrain Loss: 0.101 | Train Acc: 96.51%\n",
      "\t Val. Loss: 0.121 |  Val. Acc: 95.88%\n",
      "Epoch: 17\n",
      "\n",
      "\tTrain Loss: 0.098 | Train Acc: 96.45%\n",
      "\t Val. Loss: 0.125 |  Val. Acc: 95.81%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-f99be0fdb06f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     train_loss, train_acc = train(model, train_iterator, optimizer, criterion,\n\u001b[0m\u001b[1;32m      8\u001b[0m                                   scheduler)\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-dbbc14796f45>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, scheduler)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# update the weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m#loss and accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Environment/python/base/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Environment/python/base/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Environment/python/base/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 50\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    # train the model\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion,\n",
    "                                  scheduler)\n",
    "\n",
    "    # evaluate the model\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "\n",
    "    # save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "\n",
    "    print('Epoch: {}\\n'.format(epoch))\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T20:45:44.620344Z",
     "start_time": "2020-05-25T20:45:43.820476Z"
    }
   },
   "outputs": [],
   "source": [
    "# inference\n",
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "\n",
    "def predict(model, sentence):\n",
    "    tokenized = [tok.text\n",
    "                 for tok in nlp.tokenizer(sentence)]  # tokenize the sentence\n",
    "    indexed = [TEXT.vocab.stoi[t]\n",
    "               for t in tokenized]  # convert to integer sequence\n",
    "    length = [len(indexed)]  # compute no. of words\n",
    "    tensor = torch.LongTensor(indexed).to(device)  # convert to tensor\n",
    "    tensor = tensor.unsqueeze(1).T  # reshape in form of batch,no. of words\n",
    "    length_tensor = torch.LongTensor(length)  # convert to tensor\n",
    "    prediction = model(tensor, length_tensor)  # prediction\n",
    "    return prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T20:45:47.699843Z",
     "start_time": "2020-05-25T20:45:47.657827Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test = pd.read_csv('./data/test_tweets_anuFYb8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T20:45:48.030081Z",
     "start_time": "2020-05-25T20:45:48.022689Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31967</td>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet\n",
       "0  31963  #studiolife #aislife #requires #passion #dedic...\n",
       "1  31964   @user #white #supremacists want everyone to s...\n",
       "2  31965  safe ways to heal your #acne!!    #altwaystohe...\n",
       "3  31966  is the hp and the cursed child book up for res...\n",
       "4  31967    3rd #bihday to my amazing, hilarious #nephew..."
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T20:47:59.874200Z",
     "start_time": "2020-05-25T20:45:55.060757Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17197it [02:04, 137.79it/s]\n"
     ]
    }
   ],
   "source": [
    "prediction = []\n",
    "ids = []\n",
    "for row in tqdm(test.iterrows()):\n",
    "    ids.append(row[1]['id'])\n",
    "    prediction.append(predict(model, row[1]['tweet']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T20:47:59.925708Z",
     "start_time": "2020-05-25T20:47:59.919326Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = []\n",
    "for pred in prediction:\n",
    "    if pred > 0.5:\n",
    "        labels.append(1)\n",
    "    else:\n",
    "        labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T20:47:59.980605Z",
     "start_time": "2020-05-25T20:47:59.968663Z"
    }
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(data={'id':ids,'label':labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T20:48:00.054250Z",
     "start_time": "2020-05-25T20:48:00.023539Z"
    }
   },
   "outputs": [],
   "source": [
    "submission.to_csv('sub.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
