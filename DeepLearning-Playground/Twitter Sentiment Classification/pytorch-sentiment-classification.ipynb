{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T22:01:59.711427Z",
     "start_time": "2020-06-05T22:01:58.819072Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "from torchtext.datasets import text_classification\n",
    "NGRAMS = 2\n",
    "import os\n",
    "BATCH_SIZE = 16\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T22:27:02.923345Z",
     "start_time": "2020-06-05T22:27:02.904089Z"
    }
   },
   "outputs": [],
   "source": [
    "#Reproducing same results\n",
    "SEED = 2019\n",
    "\n",
    "#Torch\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "#Cuda algorithms\n",
    "torch.backends.cudnn.deterministic = True  \n",
    "\n",
    "#handling text data\n",
    "from torchtext import data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T22:27:05.385822Z",
     "start_time": "2020-06-05T22:27:05.381440Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T22:27:06.104171Z",
     "start_time": "2020-06-05T22:27:06.100635Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchtext.data.utils import ngrams_iterator\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T22:27:07.291048Z",
     "start_time": "2020-06-05T22:27:07.283738Z"
    }
   },
   "outputs": [],
   "source": [
    "def text_preprocessing(text_list):\n",
    "    clean_text=\" \".join(text_list)\n",
    "    clean_text = clean_text.replace(\"[^a-zA-Z0-9#]\", \" \")\n",
    "    clean_text = clean_text.replace('#', 'hashtag ')\n",
    "    clean_text = tknzr.tokenize(clean_text)\n",
    "    return clean_text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T22:07:20.424731Z",
     "start_time": "2020-06-05T22:07:11.571042Z"
    }
   },
   "outputs": [],
   "source": [
    "TEXT = data.Field(tokenize=\"spacy\",\n",
    "                  batch_first=True,\n",
    "                  include_lengths=True,\n",
    "                  lower=True,\n",
    "                  stop_words=set(stopwords.words('english')),\n",
    "                  preprocessing=text_preprocessing)\n",
    "LABEL = data.LabelField(dtype=torch.float, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T22:07:20.453266Z",
     "start_time": "2020-06-05T22:07:20.449126Z"
    }
   },
   "outputs": [],
   "source": [
    "fields = [(None, None),('label', LABEL) ,('text',TEXT)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T22:07:27.970018Z",
     "start_time": "2020-06-05T22:07:20.473491Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': '0', 'text': ['@user', 'father', 'dysfunctional', 'selfish', 'drags', 'kids', 'dysfunction', '.', 'hashtag', 'run']}\n"
     ]
    }
   ],
   "source": [
    "# loading custom train dataset\n",
    "training_data = data.TabularDataset(path='./data/train_E6oV3lV.csv',\n",
    "                                    format='csv',\n",
    "                                    fields=fields,\n",
    "                                    skip_header=True)\n",
    "\n",
    "# print preprocessed text\n",
    "print(vars(training_data.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T22:07:32.158762Z",
     "start_time": "2020-06-05T22:07:32.085496Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "train_data, valid_data = training_data.split(split_ratio=0.9,stratified=True,random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T22:07:34.552627Z",
     "start_time": "2020-06-05T22:07:33.086308Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of TEXT vocabulary: 39862\n",
      "Size of LABEL vocabulary: 2\n",
      "[('hashtag', 67699), ('@user', 15835), ('\\x9f', 15472), ('รฐ', 13644), ('!', 13187), ('.', 11048), ('\\x98', 6569), ('\\x80', 5959), (',', 5672), (\"'\", 5531)]\n"
     ]
    }
   ],
   "source": [
    "# initialize glove embeddings\n",
    "TEXT.build_vocab(train_data, min_freq=1, vectors=\"glove.6B.300d\")\n",
    "LABEL.build_vocab(train_data)\n",
    "\n",
    "# No. of unique tokens in text\n",
    "print(\"Size of TEXT vocabulary:\", len(TEXT.vocab))\n",
    "\n",
    "# No. of unique tokens in label\n",
    "print(\"Size of LABEL vocabulary:\", len(LABEL.vocab))\n",
    "\n",
    "# Commonly used words\n",
    "print(TEXT.vocab.freqs.most_common(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T22:07:37.931815Z",
     "start_time": "2020-06-05T22:07:37.920514Z"
    }
   },
   "outputs": [],
   "source": [
    "# check whether cuda is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# set batch size\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Load an iterator\n",
    "train_iterator, valid_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    sort_key=lambda x: len(x.text),\n",
    "    sort_within_batch=True,\n",
    "    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T22:07:38.865127Z",
     "start_time": "2020-06-05T22:07:38.853871Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class classifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim,\n",
    "                 n_layers, bidirectional, dropout):\n",
    "\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim,\n",
    "                            hidden_dim,\n",
    "                            num_layers=n_layers,\n",
    "                            bidirectional=bidirectional,\n",
    "                            dropout=dropout,\n",
    "                            batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.act = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, text, text_lengths):\n",
    "        # text = [batch size,sent_length]\n",
    "        embedded = self.embedding(text)\n",
    "        # embedded = [batch size, sent_len, emb dim]\n",
    "        # packed sequence\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded,\n",
    "                                                            text_lengths,\n",
    "                                                            batch_first=True)\n",
    "        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n",
    "        # hidden = [batch size, num layers * num directions,hid dim]\n",
    "        # cell = [batch size, num layers * num directions,hid dim]\n",
    "        # concat the final forward and backward hidden state\n",
    "        hidden = torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)\n",
    "        # hidden = [batch size, hid dim * num directions]\n",
    "        dense_outputs = self.fc(hidden)\n",
    "        # Final activation function\n",
    "        outputs = self.act(dense_outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T22:07:39.688166Z",
     "start_time": "2020-06-05T22:07:39.581149Z"
    }
   },
   "outputs": [],
   "source": [
    "# define hyperparameters\n",
    "size_of_vocab = len(TEXT.vocab)\n",
    "embedding_dim = 300\n",
    "num_hidden_nodes = 32\n",
    "num_output_nodes = 1\n",
    "num_layers = 2\n",
    "bidirection = True\n",
    "dropout = 0.5\n",
    "\n",
    "# instantiate the model\n",
    "model = classifier(size_of_vocab,\n",
    "                   embedding_dim,\n",
    "                   num_hidden_nodes,\n",
    "                   num_output_nodes,\n",
    "                   num_layers,\n",
    "                   bidirectional=True,\n",
    "                   dropout=dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T22:07:40.816944Z",
     "start_time": "2020-06-05T22:07:40.798234Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier(\n",
      "  (embedding): Embedding(39862, 300)\n",
      "  (lstm): LSTM(300, 32, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
      "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (act): Sigmoid()\n",
      ")\n",
      "The model has 12,069,257 trainable parameters\n",
      "torch.Size([39862, 300])\n"
     ]
    }
   ],
   "source": [
    "#architecture\n",
    "print(model)\n",
    "\n",
    "#No. of trianable parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "#Initialize the pretrained embedding\n",
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "\n",
    "print(pretrained_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T22:07:41.807155Z",
     "start_time": "2020-06-05T22:07:41.798809Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# define optimizer and loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss()\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)\n",
    "\n",
    "\n",
    "# define metric\n",
    "def binary_accuracy(preds, y):\n",
    "    # round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "\n",
    "    correct = (rounded_preds == y).float()\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "\n",
    "# push to cuda if available\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T22:07:42.548939Z",
     "start_time": "2020-06-05T22:07:42.539545Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, scheduler):\n",
    "\n",
    "    # initialize every epoch\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    # set the model in training phase\n",
    "    model.train()\n",
    "\n",
    "    for batch in iterator:\n",
    "\n",
    "        # resets the gradients after every batch\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # retrieve text and no. of words\n",
    "        text, text_lengths = batch.text\n",
    "\n",
    "        # convert to 1D tensor\n",
    "        predictions = model(text, text_lengths).squeeze()\n",
    "\n",
    "        # compute the loss\n",
    "        loss = criterion(predictions, batch.label)\n",
    "\n",
    "        # compute the binary accuracy\n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "        # backpropage the loss and compute the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        #loss and accuracy\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    scheduler.step()\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T22:07:43.381434Z",
     "start_time": "2020-06-05T22:07:43.371509Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "\n",
    "    # initialize every epoch\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    # deactivating dropout layers\n",
    "    model.eval()\n",
    "\n",
    "    # deactivates autograd\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for batch in iterator:\n",
    "\n",
    "            # retrieve text and no. of words\n",
    "            text, text_lengths = batch.text\n",
    "\n",
    "            # convert to 1d tensor\n",
    "            predictions = model(text, text_lengths).squeeze()\n",
    "\n",
    "            # compute loss and accuracy\n",
    "            loss = criterion(predictions, batch.label)\n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "            # keep track of loss and accuracy\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T22:09:47.949321Z",
     "start_time": "2020-06-05T22:07:44.110895Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Length of all samples has to be greater than 0, but found an element in 'lengths' that is <= 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-f99be0fdb06f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     train_loss, train_acc = train(model, train_iterator, optimizer, criterion,\n\u001b[0;32m----> 8\u001b[0;31m                                   scheduler)\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-dbbc14796f45>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, scheduler)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# convert to 1D tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# compute the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pythonenv/default/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-6df3963b7ce5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, text, text_lengths)\u001b[0m\n\u001b[1;32m     24\u001b[0m         packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded,\n\u001b[1;32m     25\u001b[0m                                                             \u001b[0mtext_lengths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                                                             batch_first=True)\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mpacked_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_embedded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# hidden = [batch size, num layers * num directions,hid dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pythonenv/default/lib/python3.7/site-packages/torch/nn/utils/rnn.py\u001b[0m in \u001b[0;36mpack_padded_sequence\u001b[0;34m(input, lengths, batch_first, enforce_sorted)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_packed_sequence_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Length of all samples has to be greater than 0, but found an element in 'lengths' that is <= 0"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 50\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    # train the model\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion,\n",
    "                                  scheduler)\n",
    "\n",
    "    # evaluate the model\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "\n",
    "    # save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "\n",
    "    print('Epoch: {}\\n'.format(epoch))\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T20:45:44.620344Z",
     "start_time": "2020-05-25T20:45:43.820476Z"
    }
   },
   "outputs": [],
   "source": [
    "# inference\n",
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "\n",
    "def predict(model, sentence):\n",
    "    tokenized = [tok.text\n",
    "                 for tok in nlp.tokenizer(sentence)]  # tokenize the sentence\n",
    "    indexed = [TEXT.vocab.stoi[t]\n",
    "               for t in tokenized]  # convert to integer sequence\n",
    "    length = [len(indexed)]  # compute no. of words\n",
    "    tensor = torch.LongTensor(indexed).to(device)  # convert to tensor\n",
    "    tensor = tensor.unsqueeze(1).T  # reshape in form of batch,no. of words\n",
    "    length_tensor = torch.LongTensor(length)  # convert to tensor\n",
    "    prediction = model(tensor, length_tensor)  # prediction\n",
    "    return prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T20:45:47.699843Z",
     "start_time": "2020-05-25T20:45:47.657827Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test = pd.read_csv('./data/test_tweets_anuFYb8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T20:45:48.030081Z",
     "start_time": "2020-05-25T20:45:48.022689Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31967</td>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet\n",
       "0  31963  #studiolife #aislife #requires #passion #dedic...\n",
       "1  31964   @user #white #supremacists want everyone to s...\n",
       "2  31965  safe ways to heal your #acne!!    #altwaystohe...\n",
       "3  31966  is the hp and the cursed child book up for res...\n",
       "4  31967    3rd #bihday to my amazing, hilarious #nephew..."
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T20:47:59.874200Z",
     "start_time": "2020-05-25T20:45:55.060757Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17197it [02:04, 137.79it/s]\n"
     ]
    }
   ],
   "source": [
    "prediction = []\n",
    "ids = []\n",
    "for row in tqdm(test.iterrows()):\n",
    "    ids.append(row[1]['id'])\n",
    "    prediction.append(predict(model, row[1]['tweet']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T20:47:59.925708Z",
     "start_time": "2020-05-25T20:47:59.919326Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = []\n",
    "for pred in prediction:\n",
    "    if pred > 0.5:\n",
    "        labels.append(1)\n",
    "    else:\n",
    "        labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T20:47:59.980605Z",
     "start_time": "2020-05-25T20:47:59.968663Z"
    }
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(data={'id':ids,'label':labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T20:48:00.054250Z",
     "start_time": "2020-05-25T20:48:00.023539Z"
    }
   },
   "outputs": [],
   "source": [
    "submission.to_csv('sub.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
