# -*- coding: utf-8 -*-
"""Inceptionv3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10bYV5N2hjo6B6hbwEe1e5ahY5YFqfLxt
"""

!pip install efficientnet-pytorch
!pip install albumentations --upgrade
!pip install tez

import os
import albumentations
import pandas as pd

import torch
import torch.nn as nn
from torch.nn import functional as F
import os
import time
import torchvision
from torchvision import datasets, models, transforms
import torch.optim as optim
import numpy as np
import matplotlib.pyplot as plt
from efficientnet_pytorch import EfficientNet
from sklearn import metrics, model_selection, preprocessing
import tez
from tez.datasets import ImageDataset
from tez.callbacks import EarlyStopping

train_aug = albumentations.Compose([
            albumentations.Transpose(p=0.5),
            albumentations.HorizontalFlip(p=0.5),
            albumentations.VerticalFlip(p=0.5),
            albumentations.ShiftScaleRotate(p=0.5),
            albumentations.HueSaturationValue(
                hue_shift_limit=0.2, 
                sat_shift_limit=0.2, 
                val_shift_limit=0.2, 
                p=0.5
            ),
            albumentations.RandomBrightnessContrast(
                brightness_limit=(-0.1,0.1), 
                contrast_limit=(-0.1, 0.1), 
                p=0.5
            ),
            albumentations.Normalize(
                mean=[0.485, 0.456, 0.406], 
                std=[0.229, 0.224, 0.225], 
                max_pixel_value=255.0, 
                p=1.0
            ),
            albumentations.Cutout(p=0.5)], p=1.)
  
        
valid_aug = albumentations.Compose([
            albumentations.Normalize(
                mean=[0.485, 0.456, 0.406], 
                std=[0.229, 0.224, 0.225], 
                max_pixel_value=255.0, 
                p=1.0
            )], p=1.)

data_dir = "/content/drive/MyDrive/DataSet_ML/dataset/dataset"

dfx = pd.read_csv('/content/drive/MyDrive/DataSet_ML/dataset/dataset/train.csv')
mapping_breed = dict((v,k) for k,v in enumerate(dfx.breed.unique()))
df_train, df_valid = model_selection.train_test_split(
        dfx, test_size=0.1, random_state=42, stratify=dfx.breed.values
)

df_train = df_train.reset_index(drop=True)
df_valid = df_valid.reset_index(drop=True)

image_path = "/content/drive/MyDrive/DataSet_ML/dataset/dataset/train/"
train_image_paths = [os.path.join(image_path, x+'.jpg') for x in df_train.image_id.values]
valid_image_paths = [os.path.join(image_path, x+'.jpg') for x in df_valid.image_id.values]
train_targets = [mapping_breed[x] for x in df_train.breed.values]
valid_targets = [mapping_breed[x] for x in df_valid.breed.values]

class SnakeModel(tez.Model):
    def __init__(self, num_classes):
        super().__init__()

        self.effnet = EfficientNet.from_pretrained("efficientnet-b4")
        self.dropout = nn.Dropout(0.1)
        self.out = nn.Linear(1792, num_classes)
        self.step_scheduler_after = "epoch"
        
    def monitor_metrics(self, outputs, targets):
        if targets is None:
            return {}
        outputs = torch.argmax(outputs, dim=1).cpu().detach().numpy()
        targets = targets.cpu().detach().numpy()
        accuracy = metrics.accuracy_score(targets, outputs)
        return {"accuracy": accuracy}
    
    def fetch_optimizer(self):
        opt = torch.optim.Adam(self.parameters(), lr=3e-4)
        return opt
    
    def fetch_scheduler(self):
        sch = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(
            self.optimizer, T_0=10, T_mult=1, eta_min=1e-6, last_epoch=-1
        )
        return sch

    def forward(self, image, targets=None):
        batch_size, _, _, _ = image.shape

        x = self.effnet.extract_features(image)
        x = F.adaptive_avg_pool2d(x, 1).reshape(batch_size, -1)
        outputs = self.out(self.dropout(x))
        
        if targets is not None:
            loss = nn.CrossEntropyLoss()(outputs, targets)
            metrics = self.monitor_metrics(outputs, targets)
            return outputs, loss, metrics
        return outputs, None, None



train_dataset = ImageDataset(
    image_paths=train_image_paths,
    targets=train_targets,
    resize=(255,255),
    augmentations=train_aug,
)

valid_dataset = ImageDataset(
    image_paths=valid_image_paths,
    targets=valid_targets,
    resize=(255,255),
    augmentations=valid_aug,
)

model = SnakeModel(num_classes=dfx.breed.nunique())
es = EarlyStopping(
    monitor="valid_loss", model_path="model.bin", patience=3, mode="min"
)
model.fit(
    train_dataset,
    valid_dataset=valid_dataset,
    train_bs=32,
    valid_bs=32,
    device="cuda",
    epochs=20,
    callbacks=[es],
    fp16=True,
)
model.save("model.bin")

import os
import albumentations
import pandas as pd
import numpy as np

import tez
from tez.datasets import ImageDataset

import torch
import torch.nn as nn
from torch.nn import functional as F

from efficientnet_pytorch import EfficientNet

test_aug = albumentations.Compose([
            albumentations.Normalize(
                mean=[0.485, 0.456, 0.406], 
                std=[0.229, 0.224, 0.225], 
                max_pixel_value=255.0, 
                p=1.0
            )], p=1.)

dfx_test = pd.read_csv("/content/drive/MyDrive/DataSet_ML/dataset/dataset/test.csv")
image_path = "/content/drive/MyDrive/DataSet_ML/dataset/dataset/test/"
test_image_paths = [os.path.join(image_path, x+'.jpg') for x in dfx_test.image_id.values]
# fake targets
dfx_test['breed']=[1]*len(dfx_test)
test_targets = dfx_test.breed.values
test_dataset = ImageDataset(
    image_paths=test_image_paths,
    targets=test_targets,
    resize=(255, 255),
    augmentations=test_aug
)

class SnakeModel(tez.Model):
    def __init__(self, num_classes):
        super().__init__()

        self.effnet = EfficientNet.from_name("efficientnet-b4")
        self.dropout = nn.Dropout(0.1)
        self.out = nn.Linear(1792, num_classes)
        self.step_scheduler_after = "epoch"

    def forward(self, image, targets=None):
        batch_size, _, _, _ = image.shape

        x = self.effnet.extract_features(image)
        x = F.adaptive_avg_pool2d(x, 1).reshape(batch_size, -1)
        outputs = self.out(self.dropout(x))
        return outputs, None, None

model = SnakeModel(num_classes=dfx.breed.nunique())
model.load("model.bin")

# run inference 5 times
final_preds = None
for j in range(5):
    preds = model.predict(test_dataset,batch_size=32, n_jobs=-1, device="cuda",sampler=None)
    temp_preds = None
    for p in preds:
        if temp_preds is None:
            temp_preds = p
        else:
            temp_preds = np.vstack((temp_preds, p))
    if final_preds is None:
        final_preds = temp_preds
    else:
        final_preds += temp_preds
final_preds /= 5

final_preds = final_preds.argmax(axis=1)

dfx_test.breed = final_preds

reversed_dictionary = dict(map(reversed, mapping_breed.items()))

dfx_test.breed = dfx_test.breed.apply(lambda x : reversed_dictionary[x])

dfx_test.to_csv("effcnt.csv",index=False)

