{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "effNET.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKnVI5VBZKql"
      },
      "source": [
        "!pip install efficientnet-pytorch\n",
        "!pip install albumentations --upgrade\n",
        "!pip install tez \n",
        "!pip install densenet-pytorch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpWhhDOp-9FN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HN42kXCYjHHf"
      },
      "source": [
        "import os\n",
        "import albumentations\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import os\n",
        "import time\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "from sklearn import metrics, model_selection, preprocessing\n",
        "import tez\n",
        "from tez.datasets import ImageDataset\n",
        "from tez.callbacks import EarlyStopping\n",
        "import cv2 \n",
        "SEED = 1234\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKtSbXb6CyUY"
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cm3BHENdUV3x"
      },
      "source": [
        "train_aug = albumentations.Compose([\n",
        "            albumentations.RandomResizedCrop(300, 300, interpolation=cv2.INTER_CUBIC),\n",
        "            albumentations.Transpose(p=0.5),\n",
        "            albumentations.HorizontalFlip(p=0.5),\n",
        "            albumentations.VerticalFlip(p=0.5),\n",
        "            albumentations.ShiftScaleRotate(p=0.5),\n",
        "            albumentations.HueSaturationValue(\n",
        "                hue_shift_limit=0.2, \n",
        "                sat_shift_limit=0.2, \n",
        "                val_shift_limit=0.2, \n",
        "                p=0.5\n",
        "            ),\n",
        "            albumentations.RandomBrightnessContrast(\n",
        "                brightness_limit=(-0.1,0.1), \n",
        "                contrast_limit=(-0.1, 0.1), \n",
        "                p=0.5\n",
        "            ),\n",
        "            albumentations.Normalize(\n",
        "                mean=[0.485, 0.456, 0.406], \n",
        "                std=[0.229, 0.224, 0.225], \n",
        "                max_pixel_value=255.0, \n",
        "                p=1.0\n",
        "            ),\n",
        "            albumentations.Cutout(p=0.5)], p=1.)\n",
        "  \n",
        "        \n",
        "valid_aug = albumentations.Compose([\n",
        "            albumentations.RandomResizedCrop(300, 300,interpolation=cv2.INTER_CUBIC),\n",
        "            albumentations.Normalize(\n",
        "                mean=[0.485, 0.456, 0.406], \n",
        "                std=[0.229, 0.224, 0.225], \n",
        "                max_pixel_value=255.0, \n",
        "                p=1.0\n",
        "            )], p=1.)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URP6HkAyT-GG"
      },
      "source": [
        "data_dir = \"/content/drive/MyDrive/DataSet_ML/dataset/dataset\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znlNYom0Ts5Z"
      },
      "source": [
        "dfx = pd.read_csv('/content/drive/MyDrive/DataSet_ML/dataset/dataset/train.csv')\n",
        "mapping_breed = dict((v,k) for k,v in enumerate(dfx.breed.unique()))\n",
        "df_train, df_valid = model_selection.train_test_split(\n",
        "        dfx, test_size=0.1, random_state=0, stratify=dfx.breed.values,shuffle=True\n",
        ")\n",
        "\n",
        "df_train = df_train.reset_index(drop=True)\n",
        "df_valid = df_valid.reset_index(drop=True)\n",
        "\n",
        "image_path = \"/content/drive/MyDrive/DataSet_ML/dataset/dataset/train/\"\n",
        "train_image_paths = [os.path.join(image_path, x+'.jpg') for x in df_train.image_id.values]\n",
        "valid_image_paths = [os.path.join(image_path, x+'.jpg') for x in df_valid.image_id.values]\n",
        "train_targets = [mapping_breed[x] for x in df_train.breed.values]\n",
        "valid_targets = [mapping_breed[x] for x in df_valid.breed.values]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNuSdAMp9Nmg"
      },
      "source": [
        "from densenet_pytorch import DenseNet\n",
        "class SnakeModel_Den161(tez.Model):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.densenet = DenseNet.from_pretrained('densenet161')\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.out = nn.Linear(2208 ,  num_classes)\n",
        "        self.step_scheduler_after = \"epoch\"\n",
        "        \n",
        "    def monitor_metrics(self, outputs, targets):\n",
        "        if targets is None:\n",
        "            return {}\n",
        "        outputs = torch.argmax(outputs, dim=1).cpu().detach().numpy()\n",
        "        targets = targets.cpu().detach().numpy()\n",
        "        accuracy = metrics.accuracy_score(targets, outputs)\n",
        "        return {\"accuracy\": accuracy}\n",
        "    \n",
        "    def fetch_optimizer(self):\n",
        "        opt = torch.optim.Adam(self.parameters(), lr=3e-4)\n",
        "        return opt\n",
        "    \n",
        "    def fetch_scheduler(self):\n",
        "        sch = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "            self.optimizer, T_0=10, T_mult=1, eta_min=1e-6, last_epoch=-1\n",
        "        )\n",
        "        return sch\n",
        "\n",
        "    def forward(self, image, targets=None):\n",
        "        batch_size, _, _, _ = image.shape\n",
        "        x = self.densenet.extract_features(image)\n",
        "        x = F.adaptive_avg_pool2d(x, 1).reshape(batch_size, -1)\n",
        "        outputs = self.out(self.dropout(x))\n",
        "        if targets is not None:\n",
        "            loss = nn.CrossEntropyLoss()(outputs, targets)\n",
        "            metrics = self.monitor_metrics(outputs, targets)\n",
        "            return outputs, loss, metrics\n",
        "        return outputs, None, None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrOex-iA7GYe"
      },
      "source": [
        "class SnakeModelB4(tez.Model):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.effnet = EfficientNet.from_pretrained(\"efficientnet-b4\")\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.out = nn.Linear(1792,  num_classes)\n",
        "        self.step_scheduler_after = \"epoch\"\n",
        "        \n",
        "    def monitor_metrics(self, outputs, targets):\n",
        "        if targets is None:\n",
        "            return {}\n",
        "        outputs = torch.argmax(outputs, dim=1).cpu().detach().numpy()\n",
        "        targets = targets.cpu().detach().numpy()\n",
        "        accuracy = metrics.accuracy_score(targets, outputs)\n",
        "        return {\"accuracy\": accuracy}\n",
        "    \n",
        "    def fetch_optimizer(self):\n",
        "        opt = torch.optim.Adam(self.parameters(), lr=3e-4)\n",
        "        return opt\n",
        "    \n",
        "    def fetch_scheduler(self):\n",
        "        sch = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "            self.optimizer, T_0=10, T_mult=1, eta_min=1e-6, last_epoch=-1\n",
        "        )\n",
        "        return sch\n",
        "\n",
        "    def forward(self, image, targets=None):\n",
        "        batch_size, _, _, _ = image.shape\n",
        "        x = self.effnet.extract_features(image)\n",
        "        x = F.adaptive_avg_pool2d(x, 1).reshape(batch_size, -1)\n",
        "        outputs = self.out(self.dropout(x))\n",
        "        if targets is not None:\n",
        "            loss = nn.CrossEntropyLoss()(outputs, targets)\n",
        "            metrics = self.monitor_metrics(outputs, targets)\n",
        "            return outputs, loss, metrics\n",
        "        return outputs, None, None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGjfcJac7IC5"
      },
      "source": [
        "class SnakeModelB5(tez.Model):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.effnet = EfficientNet.from_pretrained(\"efficientnet-b5\")\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.out = nn.Linear(2048 ,  num_classes)\n",
        "        self.step_scheduler_after = \"epoch\"\n",
        "        \n",
        "    def monitor_metrics(self, outputs, targets):\n",
        "        if targets is None:\n",
        "            return {}\n",
        "        outputs = torch.argmax(outputs, dim=1).cpu().detach().numpy()\n",
        "        targets = targets.cpu().detach().numpy()\n",
        "        accuracy = metrics.accuracy_score(targets, outputs)\n",
        "        return {\"accuracy\": accuracy}\n",
        "    \n",
        "    def fetch_optimizer(self):\n",
        "        opt = torch.optim.Adam(self.parameters(), lr=3e-4)\n",
        "        return opt\n",
        "    \n",
        "    def fetch_scheduler(self):\n",
        "        sch = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "            self.optimizer, T_0=10, T_mult=1, eta_min=1e-6, last_epoch=-1\n",
        "        )\n",
        "        return sch\n",
        "\n",
        "    def forward(self, image, targets=None):\n",
        "        batch_size, _, _, _ = image.shape\n",
        "        x = self.effnet.extract_features(image)\n",
        "        x = F.adaptive_avg_pool2d(x, 1).reshape(batch_size, -1)\n",
        "        outputs = self.out(self.dropout(x))\n",
        "        if targets is not None:\n",
        "            loss = nn.CrossEntropyLoss()(outputs, targets)\n",
        "            metrics = self.monitor_metrics(outputs, targets)\n",
        "            return outputs, loss, metrics\n",
        "        return outputs, None, None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEbwgOifye2A"
      },
      "source": [
        "class SnakeModelB6(tez.Model):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.effnet = EfficientNet.from_pretrained(\"efficientnet-b6\")\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.out = nn.Linear(2304 ,  num_classes)\n",
        "        self.step_scheduler_after = \"epoch\"\n",
        "        \n",
        "    def monitor_metrics(self, outputs, targets):\n",
        "        if targets is None:\n",
        "            return {}\n",
        "        outputs = torch.argmax(outputs, dim=1).cpu().detach().numpy()\n",
        "        targets = targets.cpu().detach().numpy()\n",
        "        accuracy = metrics.accuracy_score(targets, outputs)\n",
        "        return {\"accuracy\": accuracy}\n",
        "    \n",
        "    def fetch_optimizer(self):\n",
        "        opt = torch.optim.Adam(self.parameters(), lr=3e-4)\n",
        "        return opt\n",
        "    \n",
        "    def fetch_scheduler(self):\n",
        "        sch = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "            self.optimizer, T_0=10, T_mult=1, eta_min=1e-6, last_epoch=-1\n",
        "        )\n",
        "        return sch\n",
        "\n",
        "    def forward(self, image, targets=None):\n",
        "        batch_size, _, _, _ = image.shape\n",
        "        x = self.effnet.extract_features(image)\n",
        "        x = F.adaptive_avg_pool2d(x, 1).reshape(batch_size, -1)\n",
        "        outputs = self.out(self.dropout(x))\n",
        "        if targets is not None:\n",
        "            loss = nn.CrossEntropyLoss()(outputs, targets)\n",
        "            metrics = self.monitor_metrics(outputs, targets)\n",
        "            return outputs, loss, metrics\n",
        "        return outputs, None, None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "my5XObyE5HA-"
      },
      "source": [
        "class SnakeModelB7(tez.Model):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.effnet = EfficientNet.from_pretrained(\"efficientnet-b7\")\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.out = nn.Linear(2560 ,  num_classes)\n",
        "        self.step_scheduler_after = \"epoch\"\n",
        "        \n",
        "    def monitor_metrics(self, outputs, targets):\n",
        "        if targets is None:\n",
        "            return {}\n",
        "        outputs = torch.argmax(outputs, dim=1).cpu().detach().numpy()\n",
        "        targets = targets.cpu().detach().numpy()\n",
        "        accuracy = metrics.accuracy_score(targets, outputs)\n",
        "        return {\"accuracy\": accuracy}\n",
        "    \n",
        "    def fetch_optimizer(self):\n",
        "        opt = torch.optim.Adam(self.parameters(), lr=3e-4)\n",
        "        return opt\n",
        "    \n",
        "    def fetch_scheduler(self):\n",
        "        sch = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "            self.optimizer, T_0=10, T_mult=1, eta_min=1e-6, last_epoch=-1\n",
        "        )\n",
        "        return sch\n",
        "\n",
        "    def forward(self, image, targets=None):\n",
        "        batch_size, _, _, _ = image.shape\n",
        "        x = self.effnet.extract_features(image)\n",
        "        x = F.adaptive_avg_pool2d(x, 1).reshape(batch_size, -1)\n",
        "        outputs = self.out(self.dropout(x))\n",
        "        if targets is not None:\n",
        "            loss = nn.CrossEntropyLoss()(outputs, targets)\n",
        "            metrics = self.monitor_metrics(outputs, targets)\n",
        "            return outputs, loss, metrics\n",
        "        return outputs, None, None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-86PoVse2jq"
      },
      "source": [
        "train_dataset = ImageDataset(\n",
        "    image_paths=train_image_paths,\n",
        "    targets=train_targets,\n",
        "    resize=(300,300),\n",
        "    augmentations=train_aug\n",
        ")\n",
        "\n",
        "valid_dataset = ImageDataset(\n",
        "    image_paths=valid_image_paths,\n",
        "    targets=valid_targets,\n",
        "    resize=(300,300),\n",
        "    augmentations=valid_aug,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAGz3D7KdEj4"
      },
      "source": [
        "dense_161 = SnakeModel_Den161(num_classes=dfx.breed.nunique())\n",
        "modelB4 = SnakeModelB4(num_classes=dfx.breed.nunique())\n",
        "modelB5 = SnakeModelB5(num_classes=dfx.breed.nunique())\n",
        "modelB6 = SnakeModelB6(num_classes=dfx.breed.nunique())\n",
        "modelB7 = SnakeModelB7(num_classes=dfx.breed.nunique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QABKGNuB798i"
      },
      "source": [
        "es = EarlyStopping(\n",
        "    monitor=\"valid_loss\", model_path=\"modelB4.bin\", patience=5, mode=\"min\"\n",
        ")\n",
        "modelB4.fit(\n",
        "    train_dataset,\n",
        "    valid_dataset=valid_dataset, \n",
        "    train_bs=16,\n",
        "    valid_bs=32,\n",
        "    device=\"cuda\",\n",
        "    epochs=60,\n",
        "    callbacks=[es],\n",
        "    fp16=True\n",
        ")\n",
        "# model.save(\"model.bin\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSfMOsOy7-0c"
      },
      "source": [
        "es = EarlyStopping(\n",
        "    monitor=\"valid_loss\", model_path=\"modelB5.bin\", patience=5, mode=\"min\"\n",
        ")\n",
        "modelB5.fit(\n",
        "    train_dataset,\n",
        "    valid_dataset=valid_dataset, \n",
        "    train_bs=16,\n",
        "    valid_bs=32,\n",
        "    device=\"cuda\",\n",
        "    epochs=60,\n",
        "    callbacks=[es],\n",
        "    fp16=True\n",
        ")\n",
        "# model.save(\"model.bin\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LXhejWGkn5i"
      },
      "source": [
        "es = EarlyStopping(\n",
        "    monitor=\"valid_loss\", model_path=\"modelB6.bin\", patience=5, mode=\"min\"\n",
        ")\n",
        "modelB6.fit(\n",
        "    train_dataset,\n",
        "    valid_dataset=valid_dataset, \n",
        "    train_bs=16,\n",
        "    valid_bs=32,\n",
        "    device=\"cuda\",\n",
        "    epochs=60,\n",
        "    callbacks=[es],\n",
        "    fp16=True\n",
        ")\n",
        "# model.save(\"model.bin\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyleQbRs5fQ9"
      },
      "source": [
        "\n",
        "es = EarlyStopping(\n",
        "    monitor=\"valid_loss\", model_path=\"modelB7.bin\", patience=5, mode=\"min\"\n",
        ")\n",
        "modelB7.fit(\n",
        "    train_dataset,\n",
        "    valid_dataset=valid_dataset, \n",
        "    train_bs=8,\n",
        "    valid_bs=32,\n",
        "    device=\"cuda\",\n",
        "    epochs=60,\n",
        "    callbacks=[es],\n",
        "    fp16=True,\n",
        ")\n",
        "# model.save(\"model.bin\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgFZm6q0wkjy"
      },
      "source": [
        "\n",
        "es = EarlyStopping(\n",
        "    monitor=\"valid_loss\", model_path=\"dense161.bin\", patience=5, mode=\"min\"\n",
        ")\n",
        "dense_161.fit(\n",
        "    train_dataset,\n",
        "    valid_dataset=valid_dataset, \n",
        "    train_bs=16,\n",
        "    valid_bs=32,\n",
        "    device=\"cuda\",\n",
        "    epochs=60,\n",
        "    callbacks=[es],\n",
        "    fp16=True\n",
        ")\n",
        "# model.save(\"model.bin\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVwlYSllkSb_"
      },
      "source": [
        "test_aug = albumentations.Compose([\n",
        "    albumentations.RandomResizedCrop(300, 300, interpolation=cv2.INTER_CUBIC),\n",
        "    albumentations.Transpose(p=0.5),\n",
        "    albumentations.HorizontalFlip(p=0.5),\n",
        "    albumentations.VerticalFlip(p=0.5),\n",
        "    albumentations.HueSaturationValue(\n",
        "        hue_shift_limit=0.2, \n",
        "        sat_shift_limit=0.2,\n",
        "        val_shift_limit=0.2, \n",
        "        p=0.5\n",
        "    ),\n",
        "    albumentations.RandomBrightnessContrast(\n",
        "        brightness_limit=(-0.1,0.1), \n",
        "        contrast_limit=(-0.1, 0.1), \n",
        "        p=0.5\n",
        "    ),\n",
        "    albumentations.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406], \n",
        "        std=[0.229, 0.224, 0.225], \n",
        "        max_pixel_value=255.0, \n",
        "        p=1.0\n",
        "    )\n",
        "], p=1.)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LeATUW1lzks"
      },
      "source": [
        "dfx_test = pd.read_csv(\"/content/drive/MyDrive/DataSet_ML/dataset/dataset/test.csv\")\n",
        "image_path = \"/content/drive/MyDrive/DataSet_ML/dataset/dataset/test/\"\n",
        "test_image_paths = [os.path.join(image_path, x+'.jpg') for x in dfx_test.image_id.values]\n",
        "# fake targets\n",
        "dfx_test['breed']=[1]*len(dfx_test)\n",
        "test_targets = dfx_test.breed.values\n",
        "test_dataset = ImageDataset(\n",
        "    image_paths=test_image_paths,\n",
        "    targets=test_targets,\n",
        "    resize=(300, 300),\n",
        "    augmentations=test_aug\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1EbjdDHRLPC"
      },
      "source": [
        "class SnakeModel_Dense161(tez.Model):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.densenet = DenseNet.from_pretrained('densenet161')\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.out = nn.Linear(2208, num_classes)\n",
        "        self.step_scheduler_after = \"epoch\"\n",
        "\n",
        "    def forward(self, image, targets=None):\n",
        "        batch_size, _, _, _ = image.shape\n",
        "\n",
        "        x = self.densenet.extract_features(image)\n",
        "        x = F.adaptive_avg_pool2d(x, 1).reshape(batch_size, -1)\n",
        "        outputs = self.out(self.dropout(x))\n",
        "        return outputs, None, None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnMuWfs2X_94"
      },
      "source": [
        "class SnakeModel_B4(tez.Model):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.effnet = EfficientNet.from_name(\"efficientnet-b4\")\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.out = nn.Linear(1792, num_classes)\n",
        "        self.step_scheduler_after = \"epoch\"\n",
        "\n",
        "    def forward(self, image, targets=None):\n",
        "        batch_size, _, _, _ = image.shape\n",
        "\n",
        "        x = self.effnet.extract_features(image)\n",
        "        x = F.adaptive_avg_pool2d(x, 1).reshape(batch_size, -1)\n",
        "        outputs = self.out(self.dropout(x))\n",
        "        return outputs, None, None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhDUwvxgYBSZ"
      },
      "source": [
        "class SnakeModel_B5(tez.Model):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.effnet = EfficientNet.from_name(\"efficientnet-b5\")\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.out = nn.Linear(2048, num_classes)\n",
        "        self.step_scheduler_after = \"epoch\"\n",
        "\n",
        "    def forward(self, image, targets=None):\n",
        "        batch_size, _, _, _ = image.shape\n",
        "\n",
        "        x = self.effnet.extract_features(image)\n",
        "        x = F.adaptive_avg_pool2d(x, 1).reshape(batch_size, -1)\n",
        "        outputs = self.out(self.dropout(x))\n",
        "        return outputs, None, None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkWQ2ngyANmn"
      },
      "source": [
        "class SnakeModel_B6(tez.Model):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.effnet = EfficientNet.from_name(\"efficientnet-b6\")\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.out = nn.Linear(2304, num_classes)\n",
        "        self.step_scheduler_after = \"epoch\"\n",
        "\n",
        "    def forward(self, image, targets=None):\n",
        "        batch_size, _, _, _ = image.shape\n",
        "\n",
        "        x = self.effnet.extract_features(image)\n",
        "        x = F.adaptive_avg_pool2d(x, 1).reshape(batch_size, -1)\n",
        "        outputs = self.out(self.dropout(x))\n",
        "        return outputs, None, None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGtRtSDWHdLK"
      },
      "source": [
        "class SnakeModel_B7(tez.Model):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.effnet = EfficientNet.from_name(\"efficientnet-b7\")\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.out = nn.Linear(2560, num_classes)\n",
        "        self.step_scheduler_after = \"epoch\"\n",
        "\n",
        "    def forward(self, image, targets=None):\n",
        "        batch_size, _, _, _ = image.shape\n",
        "\n",
        "        x = self.effnet.extract_features(image)\n",
        "        x = F.adaptive_avg_pool2d(x, 1).reshape(batch_size, -1)\n",
        "        outputs = self.out(self.dropout(x))\n",
        "        return outputs, None, None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFIDGDorVrGz"
      },
      "source": [
        "model_d161 = SnakeModel_Dense161(num_classes=dfx.breed.nunique())\n",
        "model_d161.load(\"dense161.bin\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEpzdeSPbwsH"
      },
      "source": [
        "\n",
        "model_d201 = SnakeModel_Dense201(num_classes=dfx.breed.nunique())\n",
        "model_d201.load(\"dense201.bin\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3yOpX8qYSMa"
      },
      "source": [
        "modelb4 = SnakeModel_B4(num_classes=dfx.breed.nunique())\n",
        "modelb4.load(\"modelB4.bin\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66oRx5_HYTDT"
      },
      "source": [
        "modelb5 = SnakeModel_B5(num_classes=dfx.breed.nunique())\n",
        "modelb5.load(\"modelB5.bin\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqT3cgeWHmvx"
      },
      "source": [
        "modelb6 = SnakeModel_B6(num_classes=dfx.breed.nunique())\n",
        "modelb6.load(\"modelB6.bin\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC7TqgAYljZr"
      },
      "source": [
        "modelb7 = SnakeModel_B7(num_classes=dfx.breed.nunique())\n",
        "modelb7.load(\"modelB7.bin\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBrnXpppHa06"
      },
      "source": [
        "# run inference 5 times\n",
        "final_preds_d201 = None\n",
        "for j in range(5):\n",
        "    preds = model_d201.predict(test_dataset,batch_size=32, n_jobs=-1, device=\"cuda\",sampler=None)\n",
        "    temp_preds = None\n",
        "    for p in preds:\n",
        "        if temp_preds is None:\n",
        "            temp_preds = p\n",
        "        else:\n",
        "            temp_preds = np.vstack((temp_preds, p))\n",
        "    if final_preds_d201 is None:\n",
        "        final_preds_d201 = temp_preds\n",
        "    else:\n",
        "        final_preds_d201 += temp_preds\n",
        "final_preds_d201 /= 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qYaQJO6V4c6"
      },
      "source": [
        "# run inference 5 times\n",
        "final_preds_d161 = None\n",
        "for j in range(5):\n",
        "    preds = model_d161.predict(test_dataset,batch_size=32, n_jobs=-1, device=\"cuda\",sampler=None)\n",
        "    temp_preds = None\n",
        "    for p in preds:\n",
        "        if temp_preds is None:\n",
        "            temp_preds = p\n",
        "        else:\n",
        "            temp_preds = np.vstack((temp_preds, p))\n",
        "    if final_preds_d161 is None:\n",
        "        final_preds_d161 = temp_preds\n",
        "    else:\n",
        "        final_preds_d161 += temp_preds\n",
        "final_preds_d161 /= 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kcH-I3KZS4A"
      },
      "source": [
        "# run inference 5 times\n",
        "final_preds_b4 = None\n",
        "for j in range(5):\n",
        "    preds = modelb4.predict(test_dataset,batch_size=32, n_jobs=-1, device=\"cuda\",sampler=None)\n",
        "    temp_preds = None\n",
        "    for p in preds:\n",
        "        if temp_preds is None:\n",
        "            temp_preds = p\n",
        "        else:\n",
        "            temp_preds = np.vstack((temp_preds, p))\n",
        "    if final_preds_b4 is None:\n",
        "        final_preds_b4 = temp_preds\n",
        "    else:\n",
        "        final_preds_b4 += temp_preds\n",
        "final_preds_b4 /= 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYAZBQH2ZT-C"
      },
      "source": [
        "# run inference 5 times\n",
        "final_preds_b5 = None\n",
        "for j in range(5):\n",
        "    preds = modelb5.predict(test_dataset,batch_size=32, n_jobs=-1, device=\"cuda\",sampler=None)\n",
        "    temp_preds = None\n",
        "    for p in preds:\n",
        "        if temp_preds is None:\n",
        "            temp_preds = p\n",
        "        else:\n",
        "            temp_preds = np.vstack((temp_preds, p))\n",
        "    if final_preds_b5 is None:\n",
        "        final_preds_b5 = temp_preds\n",
        "    else:\n",
        "        final_preds_b5 += temp_preds\n",
        "final_preds_b5 /= 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceXWLRT5ljUX"
      },
      "source": [
        "# run inference 5 times\n",
        "final_preds_b6 = None\n",
        "for j in range(5):\n",
        "    preds = modelb6.predict(test_dataset,batch_size=32, n_jobs=-1, device=\"cuda\",sampler=None)\n",
        "    temp_preds = None\n",
        "    for p in preds:\n",
        "        if temp_preds is None:\n",
        "            temp_preds = p\n",
        "        else:\n",
        "            temp_preds = np.vstack((temp_preds, p))\n",
        "    if final_preds_b6 is None:\n",
        "        final_preds_b6 = temp_preds\n",
        "    else:\n",
        "        final_preds_b6 += temp_preds\n",
        "final_preds_b6 /= 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awTAQE8WSHev"
      },
      "source": [
        "# run inference 5 times\n",
        "final_preds_b7 = None\n",
        "for j in range(5):\n",
        "    preds = modelb7.predict(test_dataset,batch_size=32, n_jobs=-1, device=\"cuda\",sampler=None)\n",
        "    temp_preds = None\n",
        "    for p in preds:\n",
        "        if temp_preds is None:\n",
        "            temp_preds = p\n",
        "        else:\n",
        "            temp_preds = np.vstack((temp_preds, p))\n",
        "    if final_preds_b7 is None:\n",
        "        final_preds_b7 = temp_preds\n",
        "    else:\n",
        "        final_preds_b7 += temp_preds\n",
        "final_preds_b7 /= 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvY4qf5-ULPN"
      },
      "source": [
        "final_preds_ensmb = (final_preds_b6 +  final_preds_b7 + final_preds_d161 + final_preds_d201)/4\n",
        "\n",
        "final_preds_ensmb = final_preds_ensmb.argmax(axis=1)\n",
        "dfx_test.breed = final_preds_ensmb\n",
        "reversed_dictionary = dict(map(reversed, mapping_breed.items()))\n",
        "dfx_test.breed = dfx_test.breed.apply(lambda x : reversed_dictionary[x])\n",
        "dfx_test.to_csv(\"effcnt_ensmb_4.csv\",index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sG0VPOnNotPd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhtP81gTlipA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDjoyDXIlg5h"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}